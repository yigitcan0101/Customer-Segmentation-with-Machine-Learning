# src/models/enhanced_neural_network.py

import tensorflow as tf
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd
import os
from datetime import datetime


class EnhancedCustomerSegmentationModel:
    """
    Enhanced Neural Network - 14 Features ile MÃ¼ÅŸteri Segmentasyonu
    ML-discovered features ile improved accuracy hedefi
    """

    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.segment_mapping = None
        self.reverse_mapping = None
        self.enhanced_feature_columns = [
            # Original RFM features (1-5)
            'Recency', 'Frequency', 'Monetary', 'AvgOrderValue', 'CustomerValue',
            # ML-discovered features (6-14)
            'auto_product_category_id', 'auto_geographic_segment_id', 'behavior_pattern_id',
            'purchase_span_days', 'order_value_consistency', 'price_tier_preference',
            'bulk_buying_tendency', 'segment_pattern_alignment', 'geographic_behavior_score'
        ]
        self.history = None

    def load_enhanced_data(self):
        """
        Enhanced TensorFlow verilerini yÃ¼kle (14 features)
        """
        print("ğŸ“Š Enhanced ML verisi yÃ¼kleniyor...")

        try:
            # Enhanced features yÃ¼kle
            X = np.load("data/processed/X_ml_enhanced_features.npy")
            y = np.load("data/processed/y_ml_enhanced_labels.npy")

            # Feature info yÃ¼kle
            with open("data/processed/ml_enhanced_feature_info.json", "r") as f:
                feature_info = json.load(f)

            self.enhanced_feature_columns = feature_info['feature_names']
            self.segment_mapping = feature_info['segment_mapping']

            # Reverse mapping oluÅŸtur
            self.reverse_mapping = {v: k for k, v in self.segment_mapping.items()}

            print(f"âœ… Enhanced veri yÃ¼klendi: {X.shape[0]} mÃ¼ÅŸteri, {X.shape[1]} enhanced feature")
            print(f"ğŸ“ˆ Enhanced Segment sayÄ±sÄ±: {len(self.segment_mapping)}")
            print(f"ğŸ·ï¸ Enhanced Segmentler: {list(self.segment_mapping.keys())}")

            # Data validation
            if X.shape[1] != 14:
                print(f"âš ï¸ UyarÄ±: Beklenen 14 feature, bulunan {X.shape[1]} feature")

            # Train/Test split (80-20)
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )

            # Enhanced feature normalization
            print("ğŸ”§ Enhanced features normalize ediliyor...")
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)

            print(f"ğŸ“Š Enhanced Training set: {X_train_scaled.shape}")
            print(f"ğŸ“‹ Enhanced Test set: {X_test_scaled.shape}")

            # Enhanced feature statistics
            print(f"\nğŸ“ˆ Enhanced Feature Ä°statistikleri:")
            for i, col in enumerate(self.enhanced_feature_columns):
                if i < X_train.shape[1]:
                    print(f"  {i + 1:2d}. {col:<25}: mean={X_train[:, i].mean():.2f}, std={X_train[:, i].std():.2f}")

            return X_train_scaled, X_test_scaled, y_train, y_test

        except FileNotFoundError as e:
            print(f"âŒ Enhanced veri dosyasÄ± bulunamadÄ±: {e}")
            print("ğŸ’¡ Ã–nce ml_auto_segmentation_engine.py Ã§alÄ±ÅŸtÄ±rÄ±n!")
            return None, None, None, None

    def build_enhanced_model(self, input_dim=14, num_classes=10):
        """
        Enhanced Neural Network mimarisi (14 features iÃ§in optimize)
        """
        print("ğŸ§  Enhanced Neural Network modeli oluÅŸturuluyor...")
        print("ğŸ¯ AmaÃ§: 14 enhanced features ile improved accuracy")

        # Enhanced Model Architecture (daha deep ve complex)
        model = tf.keras.Sequential([
            # Input layer - Enhanced marketing features
            tf.keras.layers.InputLayer(input_shape=(input_dim,), name='enhanced_marketing_features'),

            # Hidden Layer 1 - Enhanced pattern analysis (increased capacity)
            tf.keras.layers.Dense(128, activation='relu', name='enhanced_analysis_1'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.3),

            # Hidden Layer 2 - Deep customer behavior modeling
            tf.keras.layers.Dense(64, activation='relu', name='deep_customer_behavior'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.4),

            # Hidden Layer 3 - Advanced segment characteristics
            tf.keras.layers.Dense(32, activation='relu', name='advanced_segment_characteristics'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.3),

            # Hidden Layer 4 - Fine-tuned segmentation
            tf.keras.layers.Dense(16, activation='relu', name='fine_tuned_segmentation'),
            tf.keras.layers.Dropout(0.2),

            # Output layer - Enhanced segment prediction
            tf.keras.layers.Dense(num_classes, activation='softmax', name='enhanced_segment_prediction')
        ])

        # Enhanced model compilation - improved optimization
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', 'sparse_categorical_crossentropy']
        )

        self.model = model

        print("âœ… Enhanced Model oluÅŸturuldu!")
        print(f"ğŸ“Š Enhanced Model parametreleri: {model.count_params():,}")
        print(f"ğŸ¯ Target: >93.6% accuracy (original model'den daha iyi)")

        # Enhanced Model Ã¶zetini gÃ¶ster
        print(f"\nğŸ—ï¸ ENHANCED MODEL MÄ°MARÄ°SÄ°:")
        model.summary()

        return model

    def train_enhanced_model(self, X_train, X_test, y_train, y_test, epochs=100):
        """
        Enhanced model eÄŸitimi - improved performance iÃ§in optimize
        """
        print("ğŸ¯ Enhanced model eÄŸitimi baÅŸlÄ±yor...")
        print("ğŸš€ Target: Original %93.6'dan daha yÃ¼ksek accuracy")

        # Enhanced callbacks - better performance iÃ§in
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_accuracy',
                patience=20,  # Daha patient (enhanced model iÃ§in)
                restore_best_weights=True,
                verbose=1
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=10,  # Enhanced iÃ§in daha patient
                min_lr=0.00001,
                verbose=1
            ),
            tf.keras.callbacks.ModelCheckpoint(
                'data/processed/enhanced_customer_segmentation_model_best.h5',
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
        ]

        # Enhanced model eÄŸitimi
        start_time = datetime.now()

        self.history = self.model.fit(
            X_train, y_train,
            validation_data=(X_test, y_test),
            epochs=epochs,
            batch_size=32,
            callbacks=callbacks,
            verbose=1
        )

        end_time = datetime.now()
        training_duration = end_time - start_time

        print("âœ… Enhanced Model eÄŸitimi tamamlandÄ±!")
        print(f"â±ï¸ EÄŸitim sÃ¼resi: {training_duration}")

        # Enhanced eÄŸitim sonuÃ§larÄ±
        final_accuracy = max(self.history.history['val_accuracy'])
        final_loss = min(self.history.history['val_loss'])

        print(f"ğŸ¯ En iyi validation accuracy: {final_accuracy:.4f}")
        print(f"ğŸ“‰ En dÃ¼ÅŸÃ¼k validation loss: {final_loss:.4f}")

        # Performance comparison with original
        original_accuracy = 0.936  # Original model accuracy
        improvement = final_accuracy - original_accuracy

        print(f"\nğŸ“Š PERFORMANCE COMPARISON:")
        print(f"   Original Model: {original_accuracy:.3f}")
        print(f"   Enhanced Model: {final_accuracy:.3f}")
        print(f"   Improvement: {improvement:+.3f} ({improvement * 100:+.1f}%)")

        return self.history

    def evaluate_enhanced_model(self, X_test, y_test):
        """
        Enhanced model performansÄ±nÄ± deÄŸerlendir
        """
        print("ğŸ“Š Enhanced Model performansÄ± deÄŸerlendiriliyor...")

        # Test skorlarÄ±
        test_loss, test_accuracy, _ = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"âœ… Enhanced Test Accuracy: {test_accuracy:.4f}")
        print(f"ğŸ“‰ Enhanced Test Loss: {test_loss:.4f}")

        # Tahminler
        y_pred_prob = self.model.predict(X_test)
        y_pred = np.argmax(y_pred_prob, axis=1)

        # Enhanced segment bazlÄ± performans raporu
        print(f"\nğŸ“‹ ENHANCED SEGMENT BAZLI PERFORMANS RAPORU:")
        target_names = [self.reverse_mapping[i] for i in range(len(self.reverse_mapping))]
        classification_rep = classification_report(y_test, y_pred, target_names=target_names)
        print(classification_rep)

        # Enhanced confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        self.plot_enhanced_confusion_matrix(cm, target_names)

        # Feature importance analysis (enhanced features iÃ§in)
        self.analyze_feature_importance(X_test, y_test)

        return test_accuracy, y_pred, y_pred_prob

    def plot_enhanced_confusion_matrix(self, cm, target_names):
        """
        Enhanced confusion matrix gÃ¶rselleÅŸtirme
        """
        plt.figure(figsize=(14, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=target_names, yticklabels=target_names)
        plt.title('ğŸ¯ Enhanced MÃ¼ÅŸteri Segmentasyonu - Confusion Matrix\n(14 Features ile GeliÅŸtirilmiÅŸ Performans)')
        plt.xlabel('Tahmin Edilen Segment')
        plt.ylabel('GerÃ§ek Segment')
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.savefig('data/processed/enhanced_confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()

    def analyze_feature_importance(self, X_test, y_test):
        """
        Enhanced features'larÄ±n Ã¶nem analizi
        """
        print(f"\nğŸ” ENHANCED FEATURE IMPORTANCE ANALYSIS:")

        # Simple feature importance via permutation
        baseline_accuracy = self.model.evaluate(X_test, y_test, verbose=0)[1]

        feature_importance = {}

        for i, feature_name in enumerate(self.enhanced_feature_columns):
            # Create permuted version
            X_test_permuted = X_test.copy()
            np.random.shuffle(X_test_permuted[:, i])

            # Evaluate with permuted feature
            permuted_accuracy = self.model.evaluate(X_test_permuted, y_test, verbose=0)[1]
            importance = baseline_accuracy - permuted_accuracy
            feature_importance[feature_name] = importance

        # Sort by importance
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)

        print("ğŸ“Š Feature Importance Ranking:")
        for i, (feature, importance) in enumerate(sorted_features):
            category = "ğŸ¯ Original RFM" if i < 5 else "ğŸ§  ML-Discovered"
            print(f"  {i + 1:2d}. {category} {feature:<25}: {importance:.4f}")

    def plot_enhanced_training_history(self):
        """
        Enhanced eÄŸitim sÃ¼reci grafiÄŸi
        """
        if self.history is None:
            print("âŒ Enhanced Model henÃ¼z eÄŸitilmemiÅŸ!")
            return

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

        # Enhanced Accuracy grafiÄŸi
        ax1.plot(self.history.history['accuracy'], label='Training Accuracy', linewidth=2)
        ax1.plot(self.history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
        ax1.axhline(y=0.936, color='red', linestyle='--', label='Original Model (93.6%)')
        ax1.set_title('ğŸ¯ Enhanced Model Accuracy\n(14 Features ile GeliÅŸtirilmiÅŸ)')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Accuracy')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # Enhanced Loss grafiÄŸi
        ax2.plot(self.history.history['loss'], label='Training Loss', linewidth=2)
        ax2.plot(self.history.history['val_loss'], label='Validation Loss', linewidth=2)
        ax2.set_title('ğŸ“‰ Enhanced Model Loss\n(14 Features Optimization)')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Loss')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('data/processed/enhanced_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

    def predict_enhanced_customer_segment(self, customer_data):
        """
        Enhanced features ile yeni mÃ¼ÅŸteri segment tahmini
        """
        if isinstance(customer_data, list):
            if len(customer_data) != 14:
                print(f"âŒ Hata: 14 enhanced feature bekleniyor, {len(customer_data)} alÄ±ndÄ±")
                return None
            customer_data = np.array(customer_data).reshape(1, -1)

        # Enhanced normalize
        customer_scaled = self.scaler.transform(customer_data)

        # Enhanced tahmin
        prediction_prob = self.model.predict(customer_scaled)
        predicted_segment_idx = np.argmax(prediction_prob)
        predicted_segment = self.reverse_mapping[predicted_segment_idx]
        confidence = prediction_prob[0][predicted_segment_idx]

        print(f"ğŸ¯ ENHANCED MÃœÅTERÄ° SEGMENT TAHMÄ°NÄ°:")
        print(f"ğŸ“Š Enhanced girdi: 14 features")
        print(f"ğŸ·ï¸ Tahmin edilen segment: {predicted_segment}")
        print(f"ğŸ“ˆ Enhanced gÃ¼ven skoru: {confidence:.4f}")

        return predicted_segment, confidence

    def save_enhanced_model(self, model_path="data/processed/enhanced_customer_segmentation_model.h5"):
        """
        Enhanced modeli kaydet
        """
        # Enhanced model kaydet
        self.model.save(model_path)

        # Enhanced scaler kaydet
        import joblib
        joblib.dump(self.scaler, "data/processed/enhanced_scaler.pkl")

        # Enhanced segment mapping kaydet
        with open("data/processed/enhanced_segment_mapping.json", "w") as f:
            json.dump(self.segment_mapping, f)

        print(f"âœ… Enhanced Model kaydedildi: {model_path}")
        print(f"âœ… Enhanced Scaler kaydedildi: enhanced_scaler.pkl")
        print(f"âœ… Enhanced Segment mapping kaydedildi: enhanced_segment_mapping.json")

    def load_enhanced_model(self, model_path="data/processed/enhanced_customer_segmentation_model.h5"):
        """
        Enhanced modeli yÃ¼kle
        """
        try:
            self.model = tf.keras.models.load_model(model_path)

            import joblib
            self.scaler = joblib.load("data/processed/enhanced_scaler.pkl")

            with open("data/processed/enhanced_segment_mapping.json", "r") as f:
                self.segment_mapping = json.load(f)

            self.reverse_mapping = {v: k for k, v in self.segment_mapping.items()}

            print(f"âœ… Enhanced Model yÃ¼klendi: {model_path}")
            return True
        except Exception as e:
            print(f"âŒ Enhanced Model yÃ¼kleme hatasÄ±: {e}")
            return False


def main():
    """
    Enhanced Neural Network ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu
    """
    print("=" * 80)
    print("ğŸ¯ ENHANCED CUSTOMER SEGMENTATION NEURAL NETWORK")
    print("ğŸ§  14 Features ile GeliÅŸtirilmiÅŸ Segmentasyon")
    print("ğŸš€ Target: Original %93.6'dan daha yÃ¼ksek accuracy")
    print("=" * 80)

    # Enhanced Model instance
    enhanced_model = EnhancedCustomerSegmentationModel()

    # Enhanced veri yÃ¼kleme
    X_train, X_test, y_train, y_test = enhanced_model.load_enhanced_data()

    if X_train is None:
        print("âŒ Enhanced veri yÃ¼klenemedi!")
        return None

    # Enhanced model oluÅŸturma
    enhanced_model.build_enhanced_model(input_dim=X_train.shape[1], num_classes=len(enhanced_model.segment_mapping))

    # Enhanced model eÄŸitimi
    enhanced_model.train_enhanced_model(X_train, X_test, y_train, y_test, epochs=75)

    # Enhanced performans deÄŸerlendirmesi
    accuracy, y_pred, y_pred_prob = enhanced_model.evaluate_enhanced_model(X_test, y_test)

    # Enhanced grafikleri Ã§iz
    enhanced_model.plot_enhanced_training_history()

    # Enhanced model kaydet
    enhanced_model.save_enhanced_model()

    print(f"\nğŸš€ ENHANCED NEURAL NETWORK HAZIR!")
    print(f"ğŸ“Š Enhanced Final Accuracy: {accuracy:.4f}")
    print(f"ğŸ¯ Performance: {'ğŸ† IMPROVED' if accuracy > 0.936 else 'ğŸ“ˆ TRAINING NEEDED'}")

    # Enhanced demo prediction
    print(f"\nğŸ¯ Enhanced Demo Prediction:")
    demo_features = [
        30, 8, 2500.0, 312.5, 200,  # Original RFM features
        3, 2, 1, 365, 0.8, 2, 1.5, 0.7, 0.6  # Enhanced ML features
    ]

    result = enhanced_model.predict_enhanced_customer_segment(demo_features)

    return enhanced_model


if __name__ == "__main__":
    enhanced_model = main()